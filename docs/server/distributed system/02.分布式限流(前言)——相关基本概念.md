---
title: 分布式限流(前言)——相关基本概念
date: '2019-10-03 08:00:00'
sidebar: 'auto'
categories:
 - 分布式
tags:
 - 分布式
 - 高并发
 - 限流
publish: true
---
[toc]
## 一. 限流指标
### 1. TPS
**Transactions Per Second，意思是每秒事务数。**一个事务是指客户端向服务器发送请求然后服务器做出反应的过程，具体的事务定义，可以是一个接口、多个接口、一个业务流程等等。以单接口定义为事务举例，每个事务包括了如下3个过程：
1. 向服务器发请求
2. 服务器自己的内部处理（包含应用服务器、数据库服务器等）
3. 服务器返回结果给客户端
如果每秒能够完成 N 次以上3个过程，TPS 就是 N。

TPS 是软件测试结果的测量单位。我们在进行服务性能压测时，接口层面最常关注的是最大 TPS 以及接口响应时间，个人理解 TPS 可以指一组逻辑相关的请求，而服务整体处理能力取决于处理能力最低模块的TPS值。

>系统吞吐量是衡量系统性能的关键指标，按照事务的完成数量来限流是最合理的。  
但是对实操性来说，按照事务来限流并不现实。在分布式系统中完成一笔事务需要多个系统的配合。比如我们在电商系统购物，需要订单、库存、账户、支付等多个服务配合完成，有的服务需要异步返回，这样完成一笔事务花费的时间可能会很长。如果按照TPS来进行限流，时间粒度可能会很大大，很难准确评估系统的响应性能。

### 2. QPS
**Queries Per Second，意思是每秒查询率。指一台服务器每秒能够响应的查询次数**，用于衡量特定的查询服务器在规定时间内所处理流量多少，主要针对专门用于查询的服务器的性能指标，比如dns，它不包含复杂的业务逻辑处理，比如数据库中的每秒执行查询sql的次数。QPS 只是一个简单查询的统计显然，不能描述增删改等操作，显然它不够全面，所以不建议用 QPS 来描述系统整体的性能；

QPS 基本类似于 TPS，但是不同的是，对于一个事务访问，会形成一个 “ T ”；但一次 " T " 中，可能产生多次对服务器的请求，服务器对这些请求，就可计入 QPS 之中。

>如果后台只有一台服务器，那HPS和QPS是等同的。但是在分布式场景下，每个请求需要多个服务器配合完成响应。

### 3. RPS
**RPS（Request per second），每秒请求数。**如果一个用户点击了一次，调用了 2 次订单服务，调用了 2次库存服务，调用了 1 次积分服务，可描述整体理解为3个RPS。

### 4.HPS
**HPS（Hits Per Second）每秒点击数**

Hit 一般在性能测试中，**都用来描述 HTTP Request**。但是，也有一些人用它描述真正的客户在界面上的点击次数。

>如果一个请求完成一笔事务，那TPS和HPS是等同的。但在分布式场景下，完成一笔事务可能需要多次请求，所以TPS和HPS指标不能等同看待。

### 5. CPS/CPM

CPS/CPM：Calls Per Second/ Calls Per Minutes，每秒 / 每分钟调用次数。

这个描述在接口级是经常用到的，比如说上面的订单服务。显然一次客户界面上的点击调用两次。
### 6. 响应时间
Response-time（响应时间RT）是执行一个请求从开始到最后收到响应数据所花费的总体时间,即从客户端发起请求到收到服务器响应结果的时间。

响应时间RT，是一个系统最重要的指标之一，它的数值大小直接反应了系统的快慢。

### 7. 并发数

并发数是指系统同时能处理的请求数量，这个也是反应了系统的负载能力。

### 8. 吞吐量

Throughput系统的吞吐量（承压能力）是指系统在单位时间内处理请求的数量，表现了一个系统的承压能力。与request对CPU的消耗、外部接口、IO等等紧密关联。单个request 对CPU消耗越高，外部系统接口、IO速度越慢，系统吞吐能力越低，反之越高。

>系统吞吐量几个重要参数：QPS（TPS）、并发数、响应时间。
### 9. 相关计算
1. 如果是对一个查询接口压测，且这个接口内部不会再去请求其它接口，那么 TPS = QPS，否则，TPS ≠ QPS
2. 如果是容量场景，假设 N 个接口都是查询接口，且这个接口内部不会再去请求其它接口，QPS = N * TPS 
3. QPS = 并发量 / 平均响应时间
---
## 二. 计算实例
>QPS（TPS）= 并发数/平均响应时间
>
>并发数 = QPS（TPS）*平均响应时间

按二八定律来看，如果每天 80% 的访问集中在 20% 的时间里，这 20% 时间就叫做峰值时间。

>公式：( 总PV数 * 80% ) / ( 每天秒数 * 20% ) = 峰值时间每秒请求数(QPS) 

通常，我们会对在线的用户做并发度分析，在很多业务中，并发度都会低于5%，甚至1%，拿 5% 来计算，就是 10000 用户 x5%=500(TPS)，注意，不是并发线程数。如果这时响应时间是 100ms，那显然并发线程数是 500TPS/(1000ms/100ms)=50(并发线程)。

>机器：峰值时间每秒QPS / 单台机器的QPS = 需要的机器

1. 每天300w PV 的在单台机器上，这台机器需要多少QPS？
( 3000000 * 0.8 ) / (86400 * 0.2 ) = 139 (QPS)

2. 如果一台机器的QPS是58，需要几台机器来支持？
139 / 58 = 3

3. 单线程QPS公式：QPS=1000ms/RT

    * 对同一个系统而言，支持的线程数越多，QPS越高。假设一个RT是80ms,则可以很容易的计算出QPS,QPS = 1000/80 = 12.5

    * 多线程场景，如果把服务端的线程数提升到2，那么整个系统的QPS则为 2*（1000/80） = 25, 可见QPS随着线程的增加而线性增长，那QPS上不去就加线程呗，听起来很有道理，公司也说的通，但是往往现实并非如此。
    

4. 最佳线程数量

    刚好消耗完服务器的瓶颈资源的临界线程数，公式如下

    >最佳线程数量=（（线程等待时间+线程cpu时间）/线程cpu时间）* cpu数量

    特性：

    * 在达到最佳线程数的时候，线程数量继续递增，则QPS不变，而响应时间变长，持续递增线程数量，则QPS开始下降。

    * 每个系统都有其最佳线程数量，但是不同状态下，最佳线程数量是会变化的。

    * 瓶颈资源可以是CPU,可以是内存，可以是锁资源，IO资源：超过最佳线程数，导致资源的竞争，超过最佳线程数，响应时间递增。
---
## 三. 其他概念
### 1 限流
原理是监控应用流量的QPS或并发线程数等指标，当达到指定阈值时对流量进行控制，避免系统被瞬时的流量高峰冲垮，保障应用高可用性。保护自身系统防止被外部调垮。

### 2. 熔断
调用远程服务，后端服务不可避免的会产生调用失败（超时或者异常），防止应用程序不断地尝试可能超时和失败的服务，能达到应用程序执行而不必等待下游服务修正错误服务。

### 3. 降级
是指牺牲非核心的业务功能，保证核心功能的稳定运行。在后台通过开关控制，降级部分非主流程的业务功能，减轻系统依赖和性能损耗，从而提升集群的整体吞吐率。

### 4. 隔离策略

1. **线程池隔离**：针对不同的资源分别创建不同的线程池，不同服务调用都发生在不同的线程池中，在线程池排队、超时等阻塞情况时可以快速失败，并可以提供 fallback 机制。好处是隔离度比较高，单独处理某个资源；代价就是线程上下文切换的 overhead 比较大，会让机器资源碎片化，特别是对低延时的调用有比较大的影响。

2. **信号量隔离**：限制对某个资源调用的并发数，更为轻量，开销更小。但缺点是无法对慢调用自动进行降级，只能等待客户端自己超时，因此仍然可能会出现级联阻塞的情况。
